import pandas as pd
import os

# Assuming your data is in 'mls_with_headers.csv'
df = pd.read_csv('football_MLS.csv')
# print(df.head())
print(df.columns)

df =df.drop(columns =['club abbreviation', 'club/sportec id'])
df =df[:-1]
df = df.to_csv('mls stats board 2024 - 14 june 2024.csv', index=False)



                      


import pandas as pd
import os

# Define the folder name/path
folder_name = 'MLS Cleaned Dataset'

if not os.path.exists(folder_name):
    # Create the folder
    os.makedirs(folder_name)
    print(f"Folder '{folder_name}' created.")
else:
    print(f"Folder '{folder_name}' already exists.")

dd_2023 = pd.read_csv('MLS Dataset/mls stats_2023.csv')

dd_2023.columns = [col.replace('regular_season_statistics/', '') for col in dd_2023.columns]
dd_2023.columns = [col.replace('_', ' ') for col in dd_2023.columns]
# dd_2023.columns = [col.replace('/', ' ') for col in dd_2023.columns]
dd_2023=dd_2023.drop(columns =[ 'club/sportec id','created','updated','id','season id','club/created','club/updated'
                               ,'club/id','club/opta id','venue id','country id','region id' ])
dd_2023= dd_2023[9:] #removing the qualifier match only stats
dd_2023.columns = [col.replace('/', ' ') for col in dd_2023.columns]
dd_2023 = dd_2023.loc[:, ~dd_2023.columns.duplicated()]
dd_2023=dd_2023.drop(columns =['club year founded','type'])

print(dd_2023.head())

dd_2023.to_csv('MLS Cleaned Dataset/mls stats_2023 cleaned.csv', index=False)






dd_2022 = pd.read_csv('MLS Dataset/mls stats_2022.csv')

dd_2022.columns = [col.replace('regular_season_statistics/', '') for col in dd_2022.columns]
dd_2022.columns = [col.replace('_', ' ') for col in dd_2022.columns]
# dd_2023.columns = [col.replace('/', ' ') for col in dd_2023.columns]
dd_2022=dd_2022.drop(columns =[ 'club/sportec id','created','updated','id','season id','club/created','club/updated'
                               ,'club/id','club/opta id','venue id','country id','region id'])
dd_2022= dd_2022[2:] #removing the qualifier match only stats
dd_2022.columns = [col.replace('/', ' ') for col in dd_2022.columns]
dd_2022 = dd_2022.loc[:, ~dd_2022.columns.duplicated()]
dd_2022=dd_2022.drop(columns =['club year founded','type'])

# print(dd_2022.head())

dd_2022.to_csv('MLS Cleaned Dataset/mls stats_2022 cleaned.csv', index=False)
dd_2022


dd_2021 = pd.read_csv('MLS Dataset/mls stats_2021.csv')

dd_2021.columns = [col.replace('regular_season_statistics/', '') for col in dd_2021.columns]
dd_2021.columns = [col.replace('_', ' ') for col in dd_2021.columns]
# dd_2023.columns = [col.replace('/', ' ') for col in dd_2023.columns]
dd_2021=dd_2021.drop(columns =[ 'club/sportec id','created','updated','id','season id','club/created','club/updated'
                               ,'club/id','club/opta id','venue id','country id','region id'])
# dd_2021= dd_2022[2:] #removing the qualifier match only stats
dd_2021.columns = [col.replace('/', ' ') for col in dd_2021.columns]
dd_2021 = dd_2021.loc[:, ~dd_2021.columns.duplicated()]
dd_2021=dd_2021.drop(columns =['club year founded','type'])
dd_2021 = dd_2021[:-1]
# # print(dd_2022.head())

dd_2021.to_csv('MLS Cleaned Dataset/mls stats_2021 cleaned.csv', index=False)
dd_2021.columns


dd_2020 = pd.read_csv('MLS Dataset/mls stats_2020.csv')

dd_2020.columns = [col.replace('regular_season_statistics/', '') for col in dd_2020.columns]
dd_2020.columns = [col.replace('_', ' ') for col in dd_2020.columns]
# dd_2023.columns = [col.replace('/', ' ') for col in dd_2023.columns]
dd_2020 =dd_2020.drop(columns =[ 'club/sportec id','created','updated','id','season id','club/created','club/updated'
                               ,'club/id','club/opta id','venue id','country id','region id'])
# dd_2021= dd_2022[2:] #removing the qualifier match only stats
dd_2020.columns = [col.replace('/', ' ') for col in dd_2020.columns]
dd_2020 = dd_2020.loc[:, ~dd_2020.columns.duplicated()]
dd_2020=dd_2020.drop(columns =['club year founded','type'])
dd_2020 = dd_2020[:-3]
dd_2020 = dd_2020.loc[~dd_2020['club id'].isin([4821, 4822])]
# # print(dd_2022.head())

dd_2020.to_csv('MLS Cleaned Dataset/mls stats_2020 cleaned.csv', index=False)
dd_2020.columns


# Function to clean the dataset
def clean_dataset_11_19(df):
    df.columns = [col.replace('regular_season_statistics/', '') for col in df.columns]
    df.columns = [col.replace('_', ' ') for col in df.columns]
    df = df.drop(columns=['club abbreviation', 'club/sportec id', 'created', 'updated', 'id', 'season id',
                          'club/created', 'club/updated', 'club/id', 'club/opta id', 'venue id', 'country id',
                          'region id'])
    df.columns = [col.replace('/', ' ') for col in df.columns]
    df = df.loc[:, ~df.columns.duplicated()]
    df = df.drop(columns=['club year founded', 'type'])
    # df = df[:-3]
    df = df.loc[~df['club id'].isin([4821, 4822])]
    return df


# Loop over the years 2011 to 2019
for year in range(2011, 2020):
    input_path = f'MLS Dataset/mls stats_{year}.csv'
    output_path = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
    
    if os.path.exists(input_path):
        # Read the dataset
        df = pd.read_csv(input_path)
        
        # Clean the dataset
        df_cleaned = clean_dataset_11_19(df)
        
        rows, cols = df_cleaned.shape
        print(f"Dataset for {year}: {rows} rows, {cols} columns")
        # Save the cleaned dataset
        df_cleaned.to_csv(output_path, index=False)
        print(f"Cleaned dataset for {year} saved to {output_path}")
    else:
        print(f"File {input_path} does not exist")





# Initialize a list to store sets of columns from each dataset
columns_sets = []

# First loop to identify common columns
for year in range(2011, 2024):
    output_path = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
    
    if os.path.exists(output_path):
        # Read the dataset
        df = pd.read_csv(output_path)
        
        # Get the columns
        columns_sets.append(set(df.columns))
        
        # Get the number of rows and columns
        rows, cols = df.shape
        print(f"Dataset for {year}: {rows} rows, {cols} columns")

# Find common columns among all datasets
if columns_sets:
    common_columns = set.intersection(*columns_sets)
    all_columns = set.union(*columns_sets)
    excluded_columns = all_columns - common_columns

    print(f"Common columns across all datasets: {len(common_columns)} columns")
    print(common_columns)
    print(f"Excluded columns across all datasets: {len(excluded_columns)} columns")
    print(excluded_columns)
else:
    print("No datasets found.")

# Second loop to clean and save datasets with only common columns
for year in range(2011, 2024):
    output_path = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
    
    if os.path.exists(output_path):
        # Read the dataset
        df = pd.read_csv(output_path)
        
        # Keep only common columns
        df = df[list(common_columns)]
        
        # Save the cleaned dataset
        df.to_csv(output_path, index=False)
        print(f"Cleaned dataset for {year} saved with only common columns.")
    else:
        print(f"File {output_path} does not exist.")


# Function to clean the dataset and calculate points
def clean_and_calculate_points(df):
    # Clean dataset here if needed
    
    # Calculate points based on wins and draws
    df['points'] = df['total wins'] * 3 + df['total draws']
    
    return df

# Loop over the years 2011 to 2023
for year in range(2011, 2024):
    input_path = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
    
    if os.path.exists(input_path):
        # Read the dataset
        df = pd.read_csv(input_path)
        
        # Clean and calculate points
        df_with_points = clean_and_calculate_points(df)
        
        # Save the dataset with points
        df_with_points.to_csv(input_path, index=False)
        print(f"Dataset for {year} saved with points.")
    else:
        print(f"File {input_path} does not exist.")


columns_sets = []

# Loop over the years 2011 to 2023
for year in range(2011, 2024):
    output_path = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
    
    if os.path.exists(output_path):
        # Read the dataset
        df = pd.read_csv(output_path)
        
        # Get the columns
        columns_sets.append(set(df.columns))
        
        # Get the number of rows and columns
        rows, cols = df.shape
        print(f"Dataset for {year}: {rows} rows, {cols} columns")

# Find common columns among all datasets


import matplotlib.pyplot as plt
import seaborn as sns



overall_metrics = [
    'goals', 'goals conceded', 'saves', 'clean sheet',
    'accurate pass', 'successful open play pass', 'accurate long balls', 'accurate cross',
    'yellow card', 'red card', 'second yellow', 'fk foul lost', 'penalty conceded',
    'possession percentage', 'successfull short pass', 'successful dribble',
    'duel won', 'interception', 'total clearance', 'tackle success per',
    'att setpiece', 'corner taken', 'att freekick goal',
    'points', 'games played', 'total matches', 'total wins', 'total losses', 'total draws','club abbreviation'
]

goals_metrics = [
    'goals', 'att ibox goal', 'att obox goal', 'att lf goal', 'att rf goal', 'att pen goal',
    'goals conceded', 'goals conceded ibox', 'goals conceded obox',
    'points'
]

attacks_metrics = [
    'total scoring att', 'ontarget scoring att', 'att ibox goal', 'att obox goal', 'att lf goal', 'att rf goal',
    'att setpiece', 'att freekick goal',
    'points'
]

defense_metrics = [
    'saves', 'clean sheet',
    'total clearance', 'interception', 'outfielder block',
    'goals conceded', 'goals conceded ibox', 'goals conceded obox',
    'points'
]

possession_metrics = [
    'possession percentage',
    'accurate pass', 'successful open play pass', 'successful dribble',
    'points'
]




# Function to filter and compute statistics
def compute_statistics(df):
    # Filter numeric columns
    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
    
    # Compute descriptive statistics for numeric columns
    statistics = df[numeric_columns].describe()
    
    # Compute correlations for numeric columns
    correlations = df[numeric_columns].corr()
    
    return statistics, correlations

# Loop over the years 2011 to 2023
for year in range(2011, 2024):
    input_path = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
    
    if os.path.exists(input_path):
        # Read the dataset
        df = pd.read_csv(input_path)

        df_goals = df[goals_metrics]
        df_attack = df[attacks_metrics]
        df_defense = df[defense_metrics]
        df_possession = df[possession_metrics]
        

        
        # Compute statistics for numeric columns
        statistics_goals, correlations_goals = compute_statistics(df_goals)
        statistics_attack, correlations_attack = compute_statistics(df_attack)
        statistics_defense, correlations_defense = compute_statistics(df_defense)
        statistics_possession, correlations_possession = compute_statistics(df_possession)
        
        # Print statistics and correlations for the current dataset
        print(f"\nStatistics for {year}:")
        print(statistics_goals)
        
        print(f"\nCorrelation goals Matrix for {year}:")
        print(correlations_goals)
        print(f"\nCorrelation attack Matrix for {year}:")
        print(correlations_attack)
        print(f"\nCorrelation defense Matrix for {year}:")
        print(correlations_defense)
        print(f"\nCorrelation possession Matrix for {year}:")
        print(correlations_possession)


        # #Box plots
        # plt.figure(figsize=(12, 8))
        # sns.boxplot(x='club abbreviation', y='goals', data=df)
        # plt.title('Goals Scored by Team')
        # plt.xlabel('Team')
        # plt.ylabel('Goals')
        # plt.xticks(rotation=45)
        # plt.show()


        # #scatter plots
        # plt.figure(figsize=(10, 6))
        # sns.scatterplot(x='ontarget scoring att', y='goals', data=df)
        # plt.title('Goals vs Shots on Target')
        # plt.xlabel('Shots on Target')
        # plt.ylabel('Goals')
        # plt.show()

        #HEATSMAPS for goals
        print("Goals")
        plt.figure(figsize=(12, 10))
        sns.heatmap(correlations_goals, annot=True, cmap='coolwarm', fmt='.2f')
        plt.title('Correlation Goals Matrix')
        plt.show()

        #HEATSMAPS for attack
        print("\n attack")
        plt.figure(figsize=(12, 10))
        sns.heatmap(correlations_attack, annot=True, cmap='coolwarm', fmt='.2f')
        plt.title('Correlation attack Matrix')
        plt.show()

        #HEATSMAPS for defence
        print("\n defence")
        plt.figure(figsize=(12, 10))
        sns.heatmap(correlations_defense, annot=True, cmap='coolwarm', fmt='.2f')
        plt.title('Correlation defence Matrix')
        plt.show()

        #HEATSMAPS for possessions
        print("\n possessions")
        plt.figure(figsize=(12, 10))
        sns.heatmap(correlations_possession, annot=True, cmap='coolwarm', fmt='.2f')
        plt.title('Correlation possessions Matrix')
        plt.show()

        
    else:
        print(f"File {input_path} does not exist.")



# Function to calculate averages and replace original values
def replace_with_team_averages(data):
    # Select only numeric columns for averaging
    numeric_cols = data.select_dtypes(include='number').columns
    
    # Group by team and calculate averages for numeric columns
    team_averages = data.groupby('club id')[numeric_cols].mean()
    
    # Merge averages back to the original dataset based on club id
    merged_data_with_avg = pd.merge(data, team_averages, on='club id', suffixes=('', '_avg'))
    
    # Replace original numeric columns with average columns
    for col in numeric_cols:
        if '_avg' in col:
            original_col = col.replace('_avg', '')
            data[original_col] = merged_data_with_avg[col]
    
    # Drop average columns (optional)
    data = data.drop([col for col in data.columns if '_avg' in col], axis=1)
    
    return data

# Define a function to read and merge datasets
def merge_datasets(years):
    all_data = pd.DataFrame()
    
    for year in years:
        filename = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
        
        if os.path.exists(filename):
            df = pd.read_csv(filename)
            
            # Assume 'club id' is the common identifier
            df['season'] = year  # Add season column for identification
            all_data = pd.concat([all_data, df], ignore_index=True)
    
    return all_data

# Example usage
years_to_merge = range(2011, 2024)
merged_data = merge_datasets(years_to_merge)

# Set 'club id' as the index
merged_data.set_index('club id', inplace=True)

# Save merged dataset to CSV
merged_data.to_csv('MLS Cleaned Dataset/All merged.csv')

# Calculate averages and replace original values
merged_data_average = replace_with_team_averages(merged_data)

# Save the updated dataset with averages
merged_data_average.to_csv('All merged with average.csv')





# Define a function to read and merge datasets
def merge_datasets(years):
    all_data = pd.DataFrame()
    
    for year in years:
        filename = f'MLS Cleaned Dataset/mls stats_{year} cleaned.csv'
        
        if os.path.exists(filename):
            df = pd.read_csv(filename)
            
            # Assume 'club id' is the common identifier
            df['season'] = year  # Add season column for identification
            all_data = pd.concat([all_data, df], ignore_index=True)
    
    return all_data

# Function to calculate averages for each 'club id'
def calculate_team_averages(data):
    # Group by 'club id' and calculate mean for each numeric column
    numeric_cols = data.select_dtypes(include='number').columns
    team_averages = data.groupby('club id')[numeric_cols].mean()
    team_averages = team_averages.round(2)
    
    return team_averages

# Example usage
years_to_merge = range(2011, 2024)
merged_data = merge_datasets(years_to_merge)

# Calculate averages for each 'club id'
team_averages = calculate_team_averages(merged_data)

# Save team averages to CSV

team_averages.to_csv('MLS Cleaned Dataset/Team Averages.csv')

# Display or further process 'team_averages' DataFrame as needed
print("Team averages calculated and saved to 'Team Averages.csv'.")



df = pd.read_csv('MLS Cleaned Dataset/Team Averages.csv')
merged_data = pd.read_csv('MLS Cleaned Dataset/All merged.csv')
df_goals = df[goals_metrics]
df_attack = df[attacks_metrics]
df_defense = df[defense_metrics]
df_possession = df[possession_metrics]
        
goals_poss = ['']
        
        # Compute statistics for numeric columns
statistics_goals, correlations_goals = compute_statistics(df_goals)
statistics_attack, correlations_attack = compute_statistics(df_attack)
statistics_defense, correlations_defense = compute_statistics(df_defense)
statistics_possession, correlations_possession = compute_statistics(df_possession)
        
        # Print statistics and correlations for the current dataset
# print(f"\nStatistics for :")
# print(statistics_goals)
        
print(f"\nCorrelation goals Matrix :")
print(correlations_goals)
print(f"\nCorrelation attack Matrix :")
print(correlations_attack)
print(f"\nCorrelation defense Matrix :")
print(correlations_defense)
print(f"\nCorrelation possession Matrix :")
print(correlations_possession)


# Line Plot Over Time
plt.figure(figsize=(10, 6))
sns.lineplot(x='season', y='goals', hue='club abbreviation', data=merged_data)
plt.title('Goals Scored Over Time')
plt.xlabel('Season')
plt.ylabel('Goals')
plt.legend(loc='upper left')
plt.show()
plt.savefig('Goals Scored Over Time')

#Box plots
plt.figure(figsize=(12, 8))
sns.boxplot(x='club abbreviation', y='goals', data=merged_data)
plt.title('Goals Scored by Team')
plt.xlabel('Team')
plt.ylabel('Goals')
plt.xticks(rotation=45)
plt.show()
plt.savefig('Goals Scored by team')



# scatter
sns.regplot(x='goals', y='points',   data=df)
plt.title('Goals vs Points')
plt.xlabel('Goals')
plt.ylabel('Points')
plt.grid(True) 
plt.show()
# plt.savefig('Goals vs points')

# scatter
sns.regplot(x='goals conceded', y='points',   data=df)
plt.title('goals conceded  vs Points')
plt.xlabel('Goals conceded')
plt.ylabel('Points')
plt.grid(True) 
plt.show()


#HEATSMAPS for goals
print("Goals")
plt.figure(figsize=(12, 10))
sns.heatmap(correlations_goals, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Goals Matrix')
plt.show()
# plt.savefig('Correlation Goals Matrix')


#HEATSMAPS for attack
print("\n attack")
plt.figure(figsize=(12, 10))
sns.heatmap(correlations_attack, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation attack Matrix')
plt.show()
# plt.savefig('Correlation attack Matrix')


#HEATSMAPS for defence
print("\n defence")
plt.figure(figsize=(12, 10))
sns.heatmap(correlations_defense, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation defence Matrix')
plt.show()
# plt.savefig('Correlation defence Matrix')

#HEATSMAPS for possessions
print("\n possessions")
plt.figure(figsize=(12, 10))
sns.heatmap(correlations_possession, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation possessions Matrix')
plt.show()
# plt.savefig('Correlation possessions Matrix')



# #HEATSMAPS for possessions
# print("\n Testing")
# plt.figure(figsize=(12, 10))
# sns.heatmap(df['possession percentage','goals'].corr(), annot=True, cmap='coolwarm', fmt='.2f')
# plt.title('Correlation possessions Matrix')
# plt.show()
# # plt.savefig('Correlation possessions Matrix')









